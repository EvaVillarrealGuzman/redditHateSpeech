{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre procesamiento\n",
    "\n",
    "En este *notebook* se aplicará el pre-procesamiento a cada comentario de reddit. El resultado se guardará en un archivo que es similar al archivo origen, con la única diferencia que el comentario estará conformado por *strings* procesados.\n",
    "\n",
    "Se realizan los siguientes pre-procesamientos:\n",
    "1. Eliminación de emails, *quotes*, *emojis* y url en cada comentario\n",
    "2. Eliminación de *stop words*\n",
    "3. Eliminación de palabras no alfanuméricas\n",
    "4. Conversión de los lemas a minúscula\n",
    "5. Se agrega bigramas y trigramas\n",
    "6. Lematización utilizando Spacy\n",
    "7. Solo se consideran palabras cuyo *part-of-speech* son un nombre propio, un sustantivo o un pronombre. [Ver *Universal POS tags*](https://universaldependencies.org/docs/u/pos/)\n",
    "\n",
    "### Fuente\n",
    "\n",
    "- [Twitter Topic Modeling](https://towardsdatascience.com/twitter-topic-modeling-e0e3315b12e2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import spacy, gensim\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "from preprocessing_utils import give_emoji_free_text, url_free_text, \\\n",
    "email_free_text, quotes_free_text, get_lemmas, tokenize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "TEXT_FILE_READ = 'docs/reddit_data.csv'  # Text to be processed\n",
    "TEXT_SAVE_FILE = 'docs/preprocessing_reddit_data.csv'\n",
    "FILENAME_PICKLE = \"docs/tmpreddit.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_lg', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "tmpreddit = pd.read_csv(TEXT_FILE_READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function above and get tweets free of emoji's\n",
    "call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "tmpreddit['emails_free'] = tmpreddit['body'].apply(email_free_text)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "tmpreddit['quotes_free'] = tmpreddit['emails_free'].apply(quotes_free_text)\n",
    "\n",
    "# Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "tmpreddit['emoji_free'] = tmpreddit['quotes_free'].apply(call_emoji_free)\n",
    "\n",
    "#Create a new column with url free tweets\n",
    "tmpreddit['url_free'] = tmpreddit['emoji_free'].apply(url_free_text)\n",
    "\n",
    "#print(tmpreddit[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(tmpreddit['url_free'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() not in nlp.Defaults.stop_words:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "tmpreddit['tokens'] = tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build the bigram and trigram model\n",
    "bigram = gensim.models.Phrases(tmpreddit['tokens'], min_count=10, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[tmpreddit['tokens']], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['probado', 'resultado', 'sellar', 'boca', 'inodoro', 'y', 'tirar', 'cadena..', 'desarrollo:', 'tenia', 'tapa', 'apoyaba', 'totalidad', 'circunferencia', 'boca', 'inodoro,', 'ponía', 'hoja', 'diario', 'tapando', 'boca,', 'cerraba', 'tapa', 'y', 'sentaba', 'tapa,', 'bordes', 'boca', 'sellaran', 'papel.', 'tirar', 'cadena,', 'aire', 'adentro', 'copa', 'salir', 'ningun', 'y,', 'entrada', 'agua,', 'genera', 'presion', 'esté', 'tapando', 'caño', 'agarra', 'viaje', 'nomas.', 'cambié', 'tapa', 'cubre', 'todo,', 'papel', 'diario,', 'pongo', 'almohadón,', 'resultado,', 'único', 'lavar', 'almohadón', 'despues..', 'gracias', 'venir', 'a', 'tedtalk.']\n"
     ]
    }
   ],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[tmpreddit['tokens'][3]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(tmpreddit['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokens a string again\n",
    "tmpreddit['tokens_back_to_text'] = [' '.join(map(str, l)) for l in data_words_bigrams]\n",
    "\n",
    "tmpreddit['lemmas'] = tmpreddit['tokens_back_to_text'].apply(get_lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make lemmas a string again\n",
    "tmpreddit['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in tmpreddit['lemmas']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmpreddit = tmpreddit.drop_duplicates(subset=['lemmas_back_to_text'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply tokenizer\n",
    "tmpreddit['lemma_tokens'] = tmpreddit['lemmas_back_to_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           tapastar baño tirar balde agua\n",
       "1                         sopapa master tapón teñir medias\n",
       "2                          sopapa tira agua caliente balde\n",
       "3        probado resultado sellar boca inodoro tirar ca...\n",
       "4        cobrar mantenimiento carajo kjjjjjjjjj viviria...\n",
       "                               ...                        \n",
       "43488                        lista comprometer contradecir\n",
       "43495                 reir demas mem humor curar depresion\n",
       "43736            pibe x200b x200b solucion inflacion x200b\n",
       "43932                                   flaco ver x200b it\n",
       "44078    compratir carabina andar local computacion x20...\n",
       "Name: lemmas_back_to_text, Length: 27782, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = tmpreddit\n",
    "reddit['body_preprocessing'] = tmpreddit['lemmas_back_to_text']\n",
    "reddit['body_no_lemmas'] = tmpreddit['tokens_back_to_text']\n",
    "reddit.pop('emails_free')\n",
    "reddit.pop('quotes_free')\n",
    "reddit.pop('emoji_free')\n",
    "reddit.pop('url_free')\n",
    "reddit.pop('tokens')\n",
    "reddit.pop('tokens_back_to_text')\n",
    "reddit.pop('lemmas')\n",
    "reddit.pop('lemmas_back_to_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       score       id       flair  comms_num  \\\n",
      "0          1  hfw14mt  Discusion🧐          1   \n",
      "1          1  hfw41eh  Discusion🧐          0   \n",
      "2          1  hfw1ao2  Discusion🧐          0   \n",
      "3          1  hfw3jof  Discusion🧐          2   \n",
      "4          1  hfw6v4i  Discusion🧐          0   \n",
      "...      ...      ...         ...        ...   \n",
      "43488      1  hhcqvbr  Política🏛️          1   \n",
      "43495      7  hhcu8ne       IAMA🙋          0   \n",
      "43736    305  hhb96tt     Video📽️          1   \n",
      "43932      1  hhbjbiu    Noticia📰          0   \n",
      "44078      1  hheds7c  Discusion🧐          0   \n",
      "\n",
      "                                                    body comment_parent_id  \\\n",
      "0      todo para decir que tapaste el baño. tira un b...            q44kw3   \n",
      "1      sopapa primero master, si hay tapón te vas a t...           hfw14mt   \n",
      "2      Usas la sopapa, o tiras agua caliente con un b...            q44kw3   \n",
      "3      Lo que he probado que siempre me dio resultado...            q44kw3   \n",
      "4      Estas cobrando por dar mantenimiento y no sabe...            q44kw3   \n",
      "...                                                  ...               ...   \n",
      "43488  Alguno tiene la lista de todas las cosas que s...            qbru4q   \n",
      "43495  Es bueno hacer reir a los demas ;) memes y hum...           hhcskq4   \n",
      "43736  PIBE. &#x200B;. NO TENGO MUCHO TIEMPO. &#x200B...           hhb5q47   \n",
      "43932      Flaco si estás viendo ésto:. &#x200B;. DO IT!            qbn952   \n",
      "44078  comprate la carabina y anda a un local de comp...            qbm2xx   \n",
      "\n",
      "      is_replay Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
      "0         False        NaN        NaN        NaN         NaN         NaN   \n",
      "1          True        NaN        NaN        NaN         NaN         NaN   \n",
      "2         False        NaN        NaN        NaN         NaN         NaN   \n",
      "3         False        NaN        NaN        NaN         NaN         NaN   \n",
      "4         False        NaN        NaN        NaN         NaN         NaN   \n",
      "...         ...        ...        ...        ...         ...         ...   \n",
      "43488     False        NaN        NaN        NaN         NaN         NaN   \n",
      "43495      True        NaN        NaN        NaN         NaN         NaN   \n",
      "43736      True        NaN        NaN        NaN         NaN         NaN   \n",
      "43932     False        NaN        NaN        NaN         NaN         NaN   \n",
      "44078     False        NaN        NaN        NaN         NaN         NaN   \n",
      "\n",
      "      Unnamed: 12 Unnamed: 13 Unnamed: 14  \\\n",
      "0             NaN         NaN         NaN   \n",
      "1             NaN         NaN         NaN   \n",
      "2             NaN         NaN         NaN   \n",
      "3             NaN         NaN         NaN   \n",
      "4             NaN         NaN         NaN   \n",
      "...           ...         ...         ...   \n",
      "43488         NaN         NaN         NaN   \n",
      "43495         NaN         NaN         NaN   \n",
      "43736         NaN         NaN         NaN   \n",
      "43932         NaN         NaN         NaN   \n",
      "44078         NaN         NaN         NaN   \n",
      "\n",
      "                                            lemma_tokens  \\\n",
      "0                   [tapastar, baño, tirar, balde, agua]   \n",
      "1                 [sopapa, master, tapón, teñir, medias]   \n",
      "2                  [sopapa, tira, agua, caliente, balde]   \n",
      "3      [probado, resultado, sellar, boca, inodoro, ti...   \n",
      "4      [cobrar, mantenimiento, carajo, kjjjjjjjjj, vi...   \n",
      "...                                                  ...   \n",
      "43488                  [lista, comprometer, contradecir]   \n",
      "43495        [reir, demas, mem, humor, curar, depresion]   \n",
      "43736   [pibe, x200b, x200b, solucion, inflacion, x200b]   \n",
      "43932                            [flaco, ver, x200b, it]   \n",
      "44078  [compratir, carabina, andar, local, computacio...   \n",
      "\n",
      "                                      body_preprocessing  \\\n",
      "0                         tapastar baño tirar balde agua   \n",
      "1                       sopapa master tapón teñir medias   \n",
      "2                        sopapa tira agua caliente balde   \n",
      "3      probado resultado sellar boca inodoro tirar ca...   \n",
      "4      cobrar mantenimiento carajo kjjjjjjjjj viviria...   \n",
      "...                                                  ...   \n",
      "43488                      lista comprometer contradecir   \n",
      "43495               reir demas mem humor curar depresion   \n",
      "43736          pibe x200b x200b solucion inflacion x200b   \n",
      "43932                                 flaco ver x200b it   \n",
      "44078  compratir carabina andar local computacion x20...   \n",
      "\n",
      "                                          body_no_lemmas  \n",
      "0                       tapaste baño. tira balde agua pa  \n",
      "1               sopapa master, tapón vas a teñir medias!  \n",
      "2                    sopapa, o tiras agua caliente balde  \n",
      "3      probado resultado sellar boca inodoro y tirar ...  \n",
      "4      cobrando mantenimiento y carajo? kjjjjjjjjj. v...  \n",
      "...                                                  ...  \n",
      "43488                     lista comprometió; contradijo?  \n",
      "43495     reir a demas ;) memes y humor curan depresion.  \n",
      "43736  pibe. &#x200b;. tiempo. &#x200b;. solucion inf...  \n",
      "43932         flaco estás viendo ésto:. &#x200b;. do it!  \n",
      "44078  comprate carabina y anda a local computacion. ...  \n",
      "\n",
      "[27782 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reddit.to_csv(TEXT_SAVE_FILE, index=False)\n",
    "\n",
    "fileObj = open(FILENAME_PICKLE, 'wb')\n",
    "pickle.dump(tmpreddit, fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": [
    "print(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
