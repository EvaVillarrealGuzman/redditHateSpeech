{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descargar comentarios desde reddit\n",
    "\n",
    "En este *notebook* se descargan comentarios desde reddit argentina.\n",
    "\n",
    "### Fuente\n",
    "\n",
    "- [reddit-api](https://www.jcchouinard.com/reddit-api-without-api-credentials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "TEXT_SAVE_FILE = 'docs/reddit_data.csv'\n",
    "MIN_WORDS_COMMENTS = 5\n",
    "MAX_WORDS_COMMENTS = 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la conexión a Reddit con las credenciales de la API que tengamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=os.environ['REDDIT_CLIENT_ID'],\n",
    "                     client_secret=os.environ['REDDIT_CLIENT_SECRET'],\n",
    "                     user_agent=os.environ['REDDIT_USER_AGENT'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "En este paso, extraemos los comentarios de reddit Argentina.\n",
    "\n",
    "Cada *post* en reddit esta conformado por comentarios, y a la vez cada comentario puede tener respuestas. Nos interesa los comentarios en diferentes niveles, tanto los que pertenecen al *post* como los que son respuestas a otros comentarios.\n",
    "\n",
    "Los comentarios en reddit pueden ser *link* o pueden ser solo textos. Filtramos solamente los comentarios que tengan textos. Para esto obtenemos cada comentario en formato *markdown* y eliminamos aquellos que comiencen con **>**.\n",
    "\n",
    "## Estructura de datos\n",
    "\n",
    "De cada comentario que se guarde de reddit, se obtendrá con los siguientes datos:\n",
    "\n",
    "- *score*: es un puntaje que los usuarios le dan al comentario.\n",
    "- *id*: identificador de reddit.\n",
    "- *flair*: es el tipo de comentario etiquetado por reddit, por ejemplo, política, economía, humor, etc.\n",
    "- *comms_num*: número de respuestas que recibió el comentaio.\n",
    "- *comment_parent_id*: identificador del *post* o comentario al cual responde el comentario actual.\n",
    "- *is_replay*: si es *False* significa que es un comentario de un post, en caso que sea *True* significa que es una respuesta a otro comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = { \"score\":[], \"id\":[], \"flair\":[], \\\n",
    "                \"comms_num\": [],  \"body\":[], \"comment_parent_id\":[], \"is_replay\": []}\n",
    "\n",
    "for submission in reddit.subreddit('argentina').new(limit=50000):\n",
    "    submission_comm = reddit.submission(id=submission.id)\n",
    "\n",
    "    # replication of comment section of reddit post\n",
    "    def replies_of(top_level_comment, link_flair_text, topics_dict):\n",
    "        if len(top_level_comment.replies) == 0:\n",
    "            return\n",
    "        for num, comment in enumerate(top_level_comment.replies):\n",
    "            stringCleanComment = depure(comment.body)\n",
    "            if not stringCleanComment == '':\n",
    "                #print('-' * 5, stringCleanComment)\n",
    "                topics_dict[\"flair\"].append(link_flair_text)\n",
    "                topics_dict[\"score\"].append(comment.score)\n",
    "                topics_dict[\"id\"].append(comment.id)\n",
    "                topics_dict[\"is_replay\"].append(True)\n",
    "                topics_dict[\"comms_num\"].append(len(comment.replies))\n",
    "                topics_dict[\"comment_parent_id\"].append(top_level_comment.id)\n",
    "                topics_dict[\"body\"].append(depure(comment.body))\n",
    "                if len(comment.replies) == 0:\n",
    "                    return\n",
    "                replies_of(comment, link_flair_text, topics_dict)\n",
    "\n",
    "    def depure(text):\n",
    "        stringClean = \"\"\n",
    "        for cline in text.splitlines( ):\n",
    "            line = cline.strip()\n",
    "            if not line.startswith('>') and len(line) < 1500 and not line.startswith('#####&#009') and not line.startswith('######&#009;')  and not line.startswith('[Owner]')  and not line.startswith('####&#009;') and not line == '' and not line.startswith('- - - - - -'): \n",
    "                if stringClean == '':\n",
    "                    stringClean = line\n",
    "                else:\n",
    "                    stringClean = stringClean + '. ' + line\n",
    "        countWords = len(stringClean.strip().split(\" \"))\n",
    "        if countWords > MIN_WORDS_COMMENTS and countWords < MAX_WORDS_COMMENTS:\n",
    "            return stringClean\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    for count, top_level_comment in enumerate(submission_comm.comments):\n",
    "        count_comm = 0\n",
    "        try :\n",
    "            stringCleanComment = depure(top_level_comment.body)\n",
    "            if not stringCleanComment == '':\n",
    "                topics_dict[\"flair\"].append(submission.link_flair_text)\n",
    "                topics_dict[\"score\"].append(top_level_comment.score)\n",
    "                topics_dict[\"id\"].append(top_level_comment.id)\n",
    "                topics_dict[\"is_replay\"].append(False)\n",
    "                topics_dict[\"comms_num\"].append(len(top_level_comment.replies))\n",
    "                topics_dict[\"comment_parent_id\"].append(submission.id)\n",
    "                topics_dict[\"body\"].append(stringCleanComment)\n",
    "            replies_of(top_level_comment, submission.link_flair_text, topics_dict)\n",
    "        except:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Se guardan los datos obtenidos en el paso anterior en un archivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print('score ' + str(len(topics_dict['score'])))\n",
    "#print('flair ' + str(len(topics_dict['flair'])))\n",
    "#print('id ' + str(len(topics_dict['id'])))\n",
    "#print('is_replay ' + str(len(topics_dict['is_replay'])))\n",
    "#print('comms_num ' + str(len(topics_dict['comms_num'])))\n",
    "#print('comment_parent_id ' + str(len(topics_dict['comment_parent_id'])))\n",
    "#print('body ' + str(len(topics_dict['body'])))\n",
    "\n",
    "topics_data = pd.DataFrame(topics_dict)\n",
    "#print('Total ' + str(len(topics_data['score'])) )\n",
    "\n",
    "#print(topics_data.head(10))\n",
    "\n",
    "topics_data.to_csv(TEXT_SAVE_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   score       id            flair  comms_num  \\\n",
      "0      1  hgw5p7y  Humor:snoo_joy:          0   \n",
      "1      1  hgw69er  Humor:snoo_joy:          0   \n",
      "2      1  hgw6zvd            Meme💩          0   \n",
      "3      1  hgw24ns            Meme💩          0   \n",
      "4      1  hgw38x8            Meme💩          0   \n",
      "5      1  hgw2rml            Meme💩          1   \n",
      "6      1  hgw3wei            Meme💩          0   \n",
      "7      1  hgw6rim            Meme💩          0   \n",
      "8      1  hgvyymo          Video📽️          1   \n",
      "9      1  hgw40yq          Video📽️          1   \n",
      "\n",
      "                                                body comment_parent_id  \\\n",
      "0                       Wado \"el operador\" De Pedro?            q9i4uj   \n",
      "1  Este Esteban Lamothe estaba en la ficción de u...            q9i4uj   \n",
      "2  Eso porque son todos útos chupa bija.. Venga e...           hgw2528   \n",
      "3  mas verso burgués que Maximo no hay. Es la rep...            q9hut7   \n",
      "4  Ayudar con comida? Na mejor unos afiches a tod...            q9hut7   \n",
      "5             ¿Por qué si es un cerdo tiene 6 patas?            q9hut7   \n",
      "6  Mira, soy tan capitalista que por 15 mil pesos...            q9hut7   \n",
      "7  como no pueden contra elllll. lo ensucian vamo...            q9hut7   \n",
      "8  Que distópico ver la cara de Gildo en todos lo...            q9hi97   \n",
      "9                      Big Compañero is watching you           hgvyymo   \n",
      "\n",
      "   is_replay  \n",
      "0      False  \n",
      "1      False  \n",
      "2       True  \n",
      "3      False  \n",
      "4      False  \n",
      "5      False  \n",
      "6      False  \n",
      "7      False  \n",
      "8      False  \n",
      "9       True  \n"
     ]
    }
   ],
   "source": [
    "print(topics_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
