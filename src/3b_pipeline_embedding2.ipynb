{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Neuronales\n",
    "\n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importanci√≥n de librer√≠a requeridas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definici√≥n de variables globales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_READ = 'docs/preprocessing_reddit_data.csv'\n",
    "TEXT_SAVE_FILE = 'docs/reddit_data_lda.csv'\n",
    "FILENAME_PICKLE = \"docs/tmpreddit.pickle\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lectura de los comentarios de Reddit\n",
    "\n",
    "Los comentarios fueron previamente preprocesados (Ver en TODO)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(FILENAME_PICKLE, 'rb') as f:\n",
    "    df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vocabulario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df['lemma_tokens'])\n",
    "\n",
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "\n",
    "# Creating a corpus object\n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = df['lemma_tokens']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenamiento del modelo Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=processed_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.train(processed_corpus, total_examples=len(processed_corpus), epochs=100)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = []\n",
    "vocabulary = list(model.wv.key_to_index)\n",
    "\n",
    "for key in model.wv.key_to_index:\n",
    "    word_vecs.append(model.wv[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenamiento del modelo Word2Vec\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos los cl√∫sters\n",
    "\n",
    "n_clusters = 70\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "X_wvkm = kmeans.fit_transform(word_vecs)\n",
    "y_wvkm = kmeans.predict(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl√∫ster 0:\n",
      " manteco ajo estofado bifir vinagre t√© pechuga calor√≠a napolit√°n remplazo cafir higo salso dandy aderezo oliva bife ganache zapallito zanahorio\n",
      "Cl√∫ster 1:\n",
      " shotcito tirante baratisimo gesticular wrigth iamc munnnn diz asamblea bonitas.com millsbeelaneiii dharma queremir mote dolaaaar potensia caius messirve cerveceer latorrir\n",
      "Cl√∫ster 2:\n",
      " his train other every less goes common |:-|:-| about thaber without friend leave whose trading| even expensive dick little away\n",
      "Cl√∫ster 3:\n",
      " mep devaluar prendario prestaci√≥n equilibrar berso imprimar quiebra irian arbitrar puedas apalancandote estable g√°n ganancio hajajar ciudadanir debio venderlo retiran\n",
      "Cl√∫ster 4:\n",
      " kink co2 c√≥pulo carvajal shaming dolaaaar ajajajajaj cre√≠que lamentar lipomodal diversidat ononononononononoo\"#\"#\"¬°=\"¬°\"¬°=¬°1 hmmmm asteroidir http siiiiiii jsjasj ofertar freelancers clothes\n",
      "Cl√∫ster 5:\n",
      " halagador fiche migratorio adhesivo afrodescendiente afirmacion traiganmir minecraft solcito shifteado serpiente orejudo subayudante chori√© maaal comerciarir desuscribite plata.tengo porlomeno chanchul\n",
      "Cl√∫ster 6:\n",
      " had vomit peronist near eat noou road usually phat grow shadir exciting unwise generals view_link girl |**usdt**|ar196,78| failure pumper gets\n",
      "Cl√∫ster 7:\n",
      " exterminar pac√≠ficamente pedrida\\ financien sab√≠a guerrar virreinato descubiertar perpetrado wallace pulof \\*quilombo jurisdiccion 2.guerra araucano incumplimento fuerzas sedici√≥n cristianismo ~~isl√°mico~~\n",
      "Cl√∫ster 8:\n",
      " baileeee sha sigaaaaa boludex compaas camvio lsnconcho taa sungazer shawn reddredemption imajen ezped oaz eda klimatiko1111 tdabajar sub-familia msdre sigaaa\n",
      "Cl√∫ster 9:\n",
      " dar dolarizar cu demos sudar pila tatuar bols√≥n podes recibir escalar umbral culpo ahorro das adolescente ibas duster torturar vio\n",
      "Cl√∫ster 10:\n",
      " recomendado yeguo siquuerar santi putona refuta empuja vigote mitom√°n palm√≥ safamos ets ramen colabor√° kjjjjjjjjjjj juzgada anfeta tobi fara√≥n bendi\n",
      "Cl√∫ster 11:\n",
      " corredor caleta madryn arverso calchaqui 17695 resaltar chochorra olivia noroeste cdad cristishima z√°rate colectividad dina rafaelar arico c1172abi europar mb\n",
      "Cl√∫ster 12:\n",
      " sab paselar dibuja ü•∫ querria devueltar antidepresivo circuito trabajadora ilusionado islandio rambla barbero catering arrancamo dota hacertelo normalidad limpi√°ndo auspicioso\n",
      "Cl√∫ster 13:\n",
      " mastercard equilibrar adida terrex branding icbc bnb publicacion acepte etherum sugerido arbitrar vol√∫men slp al30 esterlino cumbiero gd30 minorista smart\n",
      "Cl√∫ster 14:\n",
      " etiquetado frontal reglamentaci√≥n marcial proh√≠bir ley_etiquetado timing llamativo exigir octagono desigual lipovetzky regulaci√≥n micaelar randazo impulsar defensor cocaina dun promover\n",
      "Cl√∫ster 15:\n",
      " dej√°s sec√°s senda pectoral protegia barr√≠ resortero brazar humedece√≠r chinesium botellar musculoso hormiga traspiracion sobaco islandio pladur eeeeeeeeepalir jajajajs bisfenol\n",
      "Cl√∫ster 16:\n",
      " enoje financiamiento incumplimento retratar quitarir trasladado romperlo dirijar inhabilitacion problem√°tica ambientalista gubernamental emprendedurismo empecer flote degenerados incompatibilidad disponibilidad ricota concurrir\n",
      "Cl√∫ster 17:\n",
      " casa tucum√°n contenedor copado tengan hoja patio ahogado restaurante recondito rec√≥ndito esquina municipalidad arisco poder confort visibilizar arreglado exterior fajar\n",
      "Cl√∫ster 18:\n",
      " usar constantemente pelotudear pajear escalar zorro vestir escudo exteriores japi aterciopelado healing tendriar creatividad aprovecho futanari deberiar ozono contener billie\n",
      "Cl√∫ster 19:\n",
      " posada concordia incestuosa campesino interactuo catamarca charlenlo inexplicable espejito desaf√≠o viviera considero caliento 50pe antifa dejenlo dudamente parasitaria mudanzo milffinder\n",
      "Cl√∫ster 20:\n",
      " peroodoncista freelancers text obsoleta rest aplic√° feriar constantmente repr√©s amigazo jordan muetra lazar exasperante buj√≠as yacyret√° cre√≠que anglo papelero burgo\n",
      "Cl√∫ster 21:\n",
      " feriar doxxeo ^(no mo√±ito fumona s.a yennys mayolivo amarronado legumbre aqua-hippie porr√≥n deniro embarazoso warnes anota seguirr muffin especial--------- gual\n",
      "Cl√∫ster 22:\n",
      " fichar paspado lustrar ^((no lamer alicante muchacos registrastar comodoren despierten machetear dioooo desplomar espanto fabiolar dislocar √±eryyyyyy parele√±o echarri soquete\n",
      "Cl√∫ster 23:\n",
      " postnet rasp√≥n perotti coliseo javkin fulminante –¥–æ–±—Ä—ã–π ahperomacrismo esforzarme evito computaci√≥n iniciativo eficient ken tornar flet –≤–µ—á–µ—Ä jajdkajsjajs vello hepatitis\n",
      "Cl√∫ster 24:\n",
      " va dec√≠s tinder roto so√±ar cinta coquetar monton bitcoin sorete termina carton orco guita cuero cornudo p√©rdida match empleador h√°bil\n",
      "Cl√∫ster 25:\n",
      " gual baratisimo reposteado argument palabara dolaaaar \\-whomodsthemods- precie bonitas.com aprenderir el.sistema jsjajdhajsjajsjsjjs agarrenme chicle coopted autistar trastornada alfafor edgar meritocratico\n",
      "Cl√∫ster 26:\n",
      " ballotage copi rascare ganatelo brazzers curseado habilite defraudado rarir pegarl debatiero basaduer balar xdxdxd atribuis circuncidado caritativo batacaso -nico tudno\n",
      "Cl√∫ster 27:\n",
      " mudo.- endeudamiento resolvente cubos interese modificaci√≥n problem√°tica volcar bajarmir generir lingevo subayudante sumalir representativo pens kochi despedida ligeramente p√≥nganse impotente\n",
      "Cl√∫ster 28:\n",
      " poner jajajaj detener loro pela empaquetado informar amanecer suspender indignar tomalo locura impresionante t√≠terir veniar rebajar inviable aspa haber plazar\n",
      "Cl√∫ster 29:\n",
      " jesse ‚£Ñ hyperinflation wage jajjajjaaa ‚°¶ ss oooon ‚¢ß europe ‚†≥ obliteration \\*bangs\\ childrir ‚°∞ suggest felizar ‚°º hablandono changes\n",
      "Cl√∫ster 30:\n",
      " maaalll c√°ntico mal\\ bien-informado jjjjajajajar hagamoslo exagerer cancelador e√≥n visitarlo lobotomizante perdoname feudalismo desconfir guitarrir llamenmar subsistencio macanudir vueltee kichnerism\n",
      "Cl√∫ster 31:\n",
      " macri santilli tolosa_paz jubilado form√≥s freestyler shot derogar micro macris queriar kuka ch√°vez t√≠terir macrista gradual n√©stor discusi√≥n simplificada significativamente\n",
      "Cl√∫ster 32:\n",
      " hacer clavar inc√≥modo salvar hombro llena depilar analizar tatuaje deja acusar argenti probable vestir conoces vale_pena u.u coger quer√© üòè\n",
      "Cl√∫ster 33:\n",
      " brazzers trelew sesionar hultima adri√°n dictamar maderna seguiran medina populista respectivo bulunt√° liderado nucleo soltario lamponne zu littlefinger calvito averg√ºenzar\n",
      "Cl√∫ster 34:\n",
      " perder porcentaje exacto oposici√≥n jajajajajaj legislativo visualmente ~~invertir~~ afano anticipado gremio manuel aprobem coalici√≥n plazo_fijo jodo grab√≥ arrepentido encabezar calabacito\n",
      "Cl√∫ster 35:\n",
      " rom√°ntico discernir posdebate pudrio extorsionado rarisimo admin delirar technicolor cringey muuuuuuuuuuuy lurkear mejorcito pinchila insano put√≠sima extenso comparta discursivo catamarca\n",
      "Cl√∫ster 36:\n",
      " perro abandonar pipeta razar perrito suelto incendio refugio garrapata maldad antecedente collar zombie canis angustiado bombero quietito vecino bicho paseador\n",
      "Cl√∫ster 37:\n",
      " desconexi√≥n resetee sacarno inactivada asesoramiento gracis chequero i.e recarguir brubank paiz quedemos electr√≥nicamente hajajar endeudamiento apalancandote equifax viiiido stretchly artilugio\n",
      "Cl√∫ster 38:\n",
      " mujer hombre tran trans optimista homosexual ara√±a satisfacer fajar prostituir gris dama binario zorra raimi cambio_climatico flacar boxeo cultura padrino\n",
      "Cl√∫ster 39:\n",
      " matr√≠cula quicio jajjaajja usb rosenfeld pib√© urnas 2026 locooooo auspiciant cudi cer willi gatir limpia trencito hannah coste planilla menoyo\n",
      "Cl√∫ster 40:\n",
      " largarlo mensajera aprob√© cotidiano bojack copi emperatriz subayudante framgemtado apasionir aspirarar agradezcar grandeeee graciass jajajajajajajjaja dioooooos bate devalueto bf2042 65535\n",
      "Cl√∫ster 41:\n",
      " ^^pd ^^llevame dpto. apalancandote hice manquiaste re-instalaci√≥n iot valoren n√≥mado consultoria inform√°tica mc.donalds tadil penalidad trabaj primicio irregular banqu√© pasant√≠a\n",
      "Cl√∫ster 42:\n",
      " pa√≠s √±oquis poblaci√≥n europeo pobreza inteligente legalmente tomado balas all√° lograr l√≥gico reprimir ejecutivo turismo default economico b√°s populista cruel\n",
      "Cl√∫ster 43:\n",
      " excedente iva ganancia mep cbu administrativo paypal adeudado deducci√≥n estafas deficit romperte asunci√≥n exportacion jubilatorio resetee recibo ‚ùé penalidad 50%\n",
      "Cl√∫ster 44:\n",
      " persona mascota circo personalidad necesidad pers√≥n garcha robado espect√°culo soportar gremio importancia vicu√±a abogada mejorar artes culto elijo 90% exitoso\n",
      "Cl√∫ster 45:\n",
      " desordir insultado fix lingevo censuro resolvemos reapropiado queer canaliz√° autocontrol permanezca ganatelo patriostimo provenir agradecen subayudante distinci√≥n molestarte ballotage manifieste\n",
      "Cl√∫ster 46:\n",
      " video v√≠deo tipito porno youtube loquito bonito tia archivo clickbait editado subreddit bloqueo aprobado mu√±eco vara vertical bueh p√∫blicamente fino\n",
      "Cl√∫ster 47:\n",
      " amigo amiga t√≠o atraer poronga irte jermu conversaci√≥n delincuent tranca boliche pajero interesar confirmo conto pasajero copado x2 factur disfrutelir\n",
      "Cl√∫ster 48:\n",
      " nismaniniear formalizar platita canguro sahar austria empujen pagarlo ski agradecerte aguafiesta internado facetado biscocho subsecretacer incomibl pegal contrincante ou cojedora\n",
      "Cl√∫ster 49:\n",
      " nota identificado p√°rrafo confesar repu_tina contribuyente clarin infobae aislado atacado visualmente muerde progres√≠a gringo burrada titular cipayos gba chamuyario trabajo\n",
      "Cl√∫ster 50:\n",
      " cristianismo indigenismo mesianico identitario secular lgbtqizp troskos ravenar stalin antirracismo creanmir p√∫ber operetar afan abanderir fern√°ndez_kirchner kircherismo homs provenir caritativo\n",
      "Cl√∫ster 51:\n",
      " vamooooo quito contemplaci√≥n nikon peluquerir recuper d7200 iluminarno formisfrar rediturrir traicionera destacable tl stl mejor[reclutar.bat adelgazar aguarde pesci penar gilgamesh\n",
      "Cl√∫ster 52:\n",
      " kkk vendepatriar surgimiento vagoneta ceniza metafora √∞ylar mondeda compadecer c√°pita pasividad plp agrandemo emiga dormimos sabidir robarselo mereceriamo commission preguntarmir\n",
      "Cl√∫ster 53:\n",
      " pensad verbalizast hazlo azulmoro pagartar needful  ï„Å£‚Ä¢·¥•‚Ä¢ î„Å£ inet indebido juntartir esmera us√°ndola inscribi√©ndote dolobus reinvento traduccion paenza -osito laly parti\n",
      "Cl√∫ster 54:\n",
      " kircherismo hominem http creanmir aprenda etchebarne se√±alir lacalle \"perdiste\" muzzolini negrium carajoo secular purir chroriplanero especial--------- macanudo mugrientus resurrection wi\n",
      "Cl√∫ster 55:\n",
      " jimena xiaomis dilar dear –∫–∏–Ω–æ mauriciomacri intrigado facu99 esro norris claaro desolado regalaba facf habl√°bamo veyron seriir filipina desinformado directivo\n",
      "Cl√∫ster 56:\n",
      " venir avise marcha ironir alternativo principios banca pr√°ctica tengar afganistar censurar transpirar indefendible 6_m√©s apiedrada vieja aflojar disolver clima aborta\n",
      "Cl√∫ster 57:\n",
      " seguir imb√©cil segu√≠ explicaci√≥n devaluaci√≥n tristeza socio gobernado olvido riesgo n√©stor llano seguis misi√≥n cristi bajen convencido ptm mariconear resbalar\n",
      "Cl√∫ster 58:\n",
      " scafati moj√°s ch√©verir gremlins queeeeeee ~~con rechazado esto1 junji tonny mimiiiir talar aga popero cucumelo todo~~ pletzalej agar acontecimiento desnuqueo\n",
      "Cl√∫ster 59:\n",
      " cagar cagate caga cagan hijos_puta patada cagarme reproducir vomit√© queja partir risible delincuent jodar tonelada culata jjajajaajaj cagandote suicidar cagarlo\n",
      "Cl√∫ster 60:\n",
      " jajaja pingo adivinar simp barba jajjaja pregunt cajo quedaste publique panza remix encontraste zp creible lleg√° abecedario pelegrini noch casco\n",
      "Cl√∫ster 61:\n",
      " imgur codificado cartoon d&d .mp4 animaci√≥n muetra apollo floxie10 difusion hubi√©s mason musiquitar reciclaje garde cambiaselo papelero testimonial recopilaci√≥n ortogr√°fico\n",
      "Cl√∫ster 62:\n",
      " penar amiguit pecci condensado pombero boeing grupazo oyasumi nombraste avegetado ernesto refracci√≥n pelearno pegoteado sacal boluu prode dome jaulo alucinar\n",
      "Cl√∫ster 63:\n",
      " with an your are think we just they that would will when youre right im can have or on more\n",
      "Cl√∫ster 64:\n",
      " gustar aburre sonrisa sobrevalorado ai conoc√≠ rasgo frutilla nublado clonar recagar procedo mirada estufa copado disfrutir vicu√±a adorno depilar top\n",
      "Cl√∫ster 65:\n",
      " fotografiar ~~paja~~ madlito upvoteir absorba chinofarm condensaci√≥n ceg√°bar sodomicer copter qliar galt perimetro prohibirio remojo bueeeeeeeeeeeee despreciabl parentela fresca macota\n",
      "Cl√∫ster 66:\n",
      " suba liqui pagano mep adicional especulador cepo mitigar resetee listado prendario equilibrar ranguir deflaci√≥n 2031 g√°n tequila cclnir fortalecimiento vend√©\n",
      "Cl√∫ster 67:\n",
      " plata centavo licitaci√≥n indemnizaci√≥n fierro cv cinturon repuesto broma tienda deficit beneficiar mantenimiento monotributo frenar imag√≠natar 15000 aumentir porcentaje mcdonalds\n",
      "Cl√∫ster 68:\n",
      " esper√°ramo schindler ‚ô° siomar front-end meawhogooo raoooul chasquear oskar comelar ‡º∂ ü¶Ü hotoff bagging upir rodillar retobado constructivo deciditeeeeeear awwwwwww\n",
      "Cl√∫ster 69:\n",
      " entender comprender arruinar brillante resentido innecesario entendi criminal contener guant compliz moralmente corregir ra√≠z repugnante amenaza siglo agarro tuvi√©rar incompleto\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(n_clusters):\n",
    "    mask = X_wvkm[y_wvkm == cluster]\n",
    "    idx_sort = np.argsort(X_wvkm[:,cluster])\n",
    "    words = [vocabulary[x] for x in idx_sort[:20]]\n",
    "\n",
    "    print(\"Cl√∫ster %d:\" % cluster, end='')\n",
    "    print()\n",
    "    for w in words:\n",
    "        print(' %s' % w, end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jajajajjajaajaj', 0.945906937122345),\n",
       " ('laconcho', 0.9091038703918457),\n",
       " ('bottle', 0.9089493155479431),\n",
       " ('branding', 0.8754062652587891),\n",
       " ('meanies', 0.8094251155853271),\n",
       " ('submarinar', 0.8011689186096191),\n",
       " ('golden', 0.7291918396949768),\n",
       " ('oct', 0.7138594388961792),\n",
       " ('frondizi', 0.7132689356803894),\n",
       " ('eyes', 0.7089555263519287)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# algunas predicciones\n",
    "\n",
    "model.wv.most_similar(\"rucula\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27791, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(processed_corpus, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mbkmeans_clusters(\n",
    "\tX, \n",
    "    k, \n",
    "    mb, \n",
    "    print_silhouette_values, \n",
    "):\n",
    "    \"\"\"Generate clusters and print Silhouette metrics using MBKmeans\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 50\n",
      "Silhouette coefficient: -0.00\n",
      "Inertia:1004188.0895273283\n",
      "Silhouette values:\n",
      "    Cluster 29: Size:485 | Avg:0.25 | Min:0.01 | Max: 0.43\n",
      "    Cluster 20: Size:239 | Avg:0.13 | Min:-0.07 | Max: 0.36\n",
      "    Cluster 46: Size:253 | Avg:0.12 | Min:-0.12 | Max: 0.36\n",
      "    Cluster 25: Size:168 | Avg:0.11 | Min:-0.11 | Max: 0.36\n",
      "    Cluster 24: Size:221 | Avg:0.10 | Min:-0.08 | Max: 0.32\n",
      "    Cluster 35: Size:178 | Avg:0.10 | Min:-0.08 | Max: 0.32\n",
      "    Cluster 14: Size:188 | Avg:0.10 | Min:-0.09 | Max: 0.29\n",
      "    Cluster 23: Size:203 | Avg:0.10 | Min:-0.09 | Max: 0.32\n",
      "    Cluster 11: Size:291 | Avg:0.09 | Min:-0.10 | Max: 0.31\n",
      "    Cluster 18: Size:148 | Avg:0.09 | Min:-0.09 | Max: 0.33\n",
      "    Cluster 16: Size:312 | Avg:0.09 | Min:-0.10 | Max: 0.30\n",
      "    Cluster 43: Size:299 | Avg:0.09 | Min:-0.07 | Max: 0.29\n",
      "    Cluster 26: Size:327 | Avg:0.08 | Min:-0.11 | Max: 0.31\n",
      "    Cluster 31: Size:355 | Avg:0.07 | Min:-0.10 | Max: 0.28\n",
      "    Cluster 40: Size:265 | Avg:0.07 | Min:-0.11 | Max: 0.28\n",
      "    Cluster 9: Size:318 | Avg:0.07 | Min:-0.11 | Max: 0.29\n",
      "    Cluster 1: Size:237 | Avg:0.06 | Min:-0.11 | Max: 0.26\n",
      "    Cluster 10: Size:2878 | Avg:0.06 | Min:-0.01 | Max: 0.12\n",
      "    Cluster 12: Size:141 | Avg:0.06 | Min:-0.12 | Max: 0.27\n",
      "    Cluster 22: Size:382 | Avg:0.06 | Min:-0.06 | Max: 0.17\n",
      "    Cluster 49: Size:338 | Avg:0.05 | Min:-0.14 | Max: 0.25\n",
      "    Cluster 41: Size:96 | Avg:0.04 | Min:-0.10 | Max: 0.26\n",
      "    Cluster 2: Size:128 | Avg:0.04 | Min:-0.11 | Max: 0.25\n",
      "    Cluster 0: Size:470 | Avg:0.04 | Min:-0.12 | Max: 0.24\n",
      "    Cluster 39: Size:213 | Avg:0.04 | Min:-0.14 | Max: 0.26\n",
      "    Cluster 19: Size:251 | Avg:0.03 | Min:-0.14 | Max: 0.23\n",
      "    Cluster 44: Size:120 | Avg:0.02 | Min:-0.15 | Max: 0.26\n",
      "    Cluster 48: Size:180 | Avg:0.01 | Min:-0.16 | Max: 0.21\n",
      "    Cluster 7: Size:508 | Avg:0.01 | Min:-0.14 | Max: 0.22\n",
      "    Cluster 47: Size:1866 | Avg:0.00 | Min:-0.06 | Max: 0.11\n",
      "    Cluster 45: Size:399 | Avg:-0.00 | Min:-0.17 | Max: 0.21\n",
      "    Cluster 42: Size:154 | Avg:-0.01 | Min:-0.20 | Max: 0.23\n",
      "    Cluster 21: Size:357 | Avg:-0.01 | Min:-0.16 | Max: 0.20\n",
      "    Cluster 34: Size:481 | Avg:-0.02 | Min:-0.18 | Max: 0.16\n",
      "    Cluster 4: Size:486 | Avg:-0.03 | Min:-0.18 | Max: 0.17\n",
      "    Cluster 28: Size:2255 | Avg:-0.04 | Min:-0.12 | Max: 0.05\n",
      "    Cluster 8: Size:398 | Avg:-0.04 | Min:-0.18 | Max: 0.13\n",
      "    Cluster 36: Size:1498 | Avg:-0.04 | Min:-0.15 | Max: 0.08\n",
      "    Cluster 33: Size:329 | Avg:-0.05 | Min:-0.22 | Max: 0.11\n",
      "    Cluster 17: Size:1044 | Avg:-0.05 | Min:-0.18 | Max: 0.10\n",
      "    Cluster 3: Size:1431 | Avg:-0.05 | Min:-0.20 | Max: 0.12\n",
      "    Cluster 15: Size:594 | Avg:-0.05 | Min:-0.22 | Max: 0.10\n",
      "    Cluster 6: Size:401 | Avg:-0.05 | Min:-0.20 | Max: 0.11\n",
      "    Cluster 38: Size:859 | Avg:-0.06 | Min:-0.13 | Max: 0.04\n",
      "    Cluster 32: Size:1269 | Avg:-0.06 | Min:-0.17 | Max: 0.06\n",
      "    Cluster 5: Size:838 | Avg:-0.06 | Min:-0.17 | Max: 0.08\n",
      "    Cluster 13: Size:684 | Avg:-0.07 | Min:-0.22 | Max: 0.08\n",
      "    Cluster 37: Size:1209 | Avg:-0.07 | Min:-0.17 | Max: 0.07\n",
      "    Cluster 27: Size:361 | Avg:-0.07 | Min:-0.24 | Max: 0.08\n",
      "    Cluster 30: Size:686 | Avg:-0.09 | Min:-0.21 | Max: 0.07\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(\n",
    "\tX=vectorized_docs,\n",
    "    k=50,\n",
    "    mb=500,\n",
    "    print_silhouette_values=True,\n",
    ")\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": df[\"body\"].values,\n",
    "    \"tokens\": [\" \".join(text) for text in processed_corpus],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: ver video bolu\\*\\ perooooo son√© \n",
      "Cluster 1: seguir ‚¢ß ‚†£ imb√©cil ‚°æ \n",
      "Cluster 2: llegar punto ‚¢ß ‚†£ ‚°æ \n",
      "Cluster 3: equilibrar d√≥lares mep arbitrar pesos \n",
      "Cluster 4: viejo ‚¢ß ‚†£ ‚°æ ‚°∞ \n",
      "Cluster 5: peronismo ‚°æ atribuis ‚¢ß peronista \n",
      "Cluster 6: problema ac√° mundo ‚¢ß suecia \n",
      "Cluster 7: pasar ‚¢ß ‚°æ ‚†£ ‚°∞ \n",
      "Cluster 8: t√©n ‚†£ ‚¢ß locador pod \n",
      "Cluster 9: vo ‚¢ß ‚†£ segu√≠ ‚°∞ \n",
      "Cluster 10: \\-mr argument supiste clothes agarrenme \n",
      "Cluster 11: venir m√≠nimo infierno\\ ‚†£ entero \n",
      "Cluster 12: alberto ginastera jajjaj \\*big brain \n",
      "Cluster 13: gracias ‚¢ß ‚†£ ‚°æ alegrar \n",
      "Cluster 14: va catre dec√≠s coquetar aflojo \n",
      "Cluster 15: votar voto ganar oficialismo pegarl \n",
      "Cluster 16: pensar ‚¢ß ‚†£ ‚°æ opinar \n",
      "Cluster 17: ‚¢ß ‚°æ ‚†£ ‚°∞ vivir \n",
      "Cluster 18: seguro automotor pegajoso letrar derechogenial/ \n",
      "Cluster 19: comer naaaaaah detox servira ocu \n",
      "Cluster 20: poner empaquetado persiga ropo lucifer \n",
      "Cluster 21: a√±o tener ‚¢ß ‚†£ ‚°æ \n",
      "Cluster 22: decir ‚¢ß ‚°æ ‚†£ ‚°∞ \n",
      "Cluster 23: quedar marmota ‚¢ß ‚°∞ ‚°æ \n",
      "Cluster 24: vida ‚¢ß felicidad resolvemos chotado \n",
      "Cluster 25: amigo sub-25 chonga disfrutelir migalar \n",
      "Cluster 26: salir biodegradar navegar ‚¢ß tenian \n",
      "Cluster 27: cagar cara jsjajar ‚¢ß ‚°æ \n",
      "Cluster 28: ‚¢ß ‚°æ ‚†£ childrir ‚°∞ \n",
      "Cluster 29: drop vomit appreciate performing named \n",
      "Cluster 30: ‚¢ß ‚†£ ‚°æ taruca tomar \n",
      "Cluster 31: tipo ‚†£ ‚¢ß lingevo asumio \n",
      "Cluster 32: ‚¢ß ‚†£ ‚°æ ‚£á suggest \n",
      "Cluster 33: leer ‚¢ß entender ‚†£ alegrar \n",
      "Cluster 34: gobierno intervenir reprimir ley \\*quilombo \n",
      "Cluster 35: gustar filmografiar wes anderson gusto \n",
      "Cluster 36: ‚¢ß ‚†£ ‚°æ ‚£á childrir \n",
      "Cluster 37: ‚¢ß ‚†£ ‚°æ ‚£á ‚°∞ \n",
      "Cluster 38: porquerio son√© cartoon rollin cambiaselo \n",
      "Cluster 39: hijo puta pobretonto pario palm√≥ \n",
      "Cluster 40: hablar ‚¢ß ‚†£ ‚°æ ‚£á \n",
      "Cluster 41: decir contro flaco quer√©s le√≥nida \n",
      "Cluster 42: x200b mirandar aepv aura regimos \n",
      "Cluster 43: hacer dislocar ‚¢ß ‚†£ ‚°æ \n",
      "Cluster 44: ah macri bowie ionizante peluco \n",
      "Cluster 45: querer ‚¢ß ‚†£ ‚°∞ mano \n",
      "Cluster 46: argentino patriotar presidentar agrupaci√≥n \"la \n",
      "Cluster 47: anchoar milanesas legumbre feriar capitalzmo \n",
      "Cluster 48: llamar pac-man nombre taranga poringar \n",
      "Cluster 49: pa√≠s poblaci√≥n pobreza default ‚†£ \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(50):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanguijuelas mas grandes no puede haber\n",
      "-------------\n",
      "alibaba no es el \"mayorista\"? compra en aliexpress. No te olvides que al dolar tenes que sumarle el 65% de impuestos y cuando llegue lo que compres pagas el 50% de lo que supere 50usd en impuestos de importacion\n",
      "-------------\n",
      "Les est√°n queriendo sacar a algunos *(por ahora algunos)* exchanges la capacidad de recibir transferencias bancarias. O sea, les cortan a los clientes del exchange el ingreso o extracci√≥n de pesos o d√≥lares con el CBU\n",
      "-------------\n",
      "Imag√≠nate unos botines del Rel√°mpago Marquinhos\n",
      "-------------\n",
      "El banco central tiene que arbitrar bonos para equilibrar mep y cclno es solo d√≥lar bcra.. EDIT: Tambi√©n tienen que ver que no se descalabre senebi por que hay importadores que est√°n yendo justo ah√≠ a buscar\n",
      "-------------\n",
      "hacele un whois al dominio y reportalo ante el ISP que corresponda, denunciandolo como estafa/fraude\n",
      "-------------\n",
      "Cada Macri es un shotcito de tequila\n",
      "-------------\n",
      "16 A√±os imposible bro, pero un pr√©stamo grande y bien invertido en cryptos ahora, si el bull market sigue te puede dar alt√≠simos beneficios y la posibilidad de devolver el pr√©stamo r√°pido. Btc, Eth o Sol.\n",
      "-------------\n",
      "Abri√≥ importaciones mientras hizo polvo una hiperinflaci√≥n dejandola en 1 d√≠gito (y hasta per√≠odos de deflaci√≥n)... todo en medio del quilombo del tequila y el fortalecimiento del d√≥lar. TRAEME LA URNA QUE LO VOTO\n",
      "-------------\n",
      "Jajjjaja quiropr√°ctico y mayorista...que trucazo! üòÇüòÇüòÇüòÇ\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 3\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:10]:\n",
    "    print( df[\"body\"].values[d])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv(TEXT_FILE_READ)\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: (x[1]), reverse=True)\n",
    "        # row = sorted(row, key=lambda x: (x[1]), reverse=True) # old line\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "                #ent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4)]), ignore_index=True)\n",
    "                #print(sent_topics_df)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    #sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    #contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, texts], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=base_model, corpus=corpus, texts=reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>is_replay</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>body_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>√©l, recordar, pegar, √∫nico, robar, barrio, pen...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw77qe</td>\n",
       "      <td>Pol√≠ticaüèõÔ∏è</td>\n",
       "      <td>0</td>\n",
       "      <td>Iba a decir, bue si lo saco de su bolsillo... ...</td>\n",
       "      <td>q9imco</td>\n",
       "      <td>False</td>\n",
       "      <td>['bue', 'saco', 'bolsillo', 'recorder', 'hdp',...</td>\n",
       "      <td>bue saco bolsillo recorder hdp mantener alcanz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2598</td>\n",
       "      <td>perro, nik, meme, gobierno, explicar, it, teni...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw7dci</td>\n",
       "      <td>Pol√≠ticaüèõÔ∏è</td>\n",
       "      <td>0</td>\n",
       "      <td>Se volvio un meme el bot del dolar?</td>\n",
       "      <td>hgw666m</td>\n",
       "      <td>True</td>\n",
       "      <td>['volvio', 'meme', 'dolar']</td>\n",
       "      <td>volvio meme dolar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.3279</td>\n",
       "      <td>falacia, decir, gratis, k, joda, pa√≠s, mandar,...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw69er</td>\n",
       "      <td>Humor:snoo_joy:</td>\n",
       "      <td>0</td>\n",
       "      <td>Este Esteban Lamothe estaba en la ficci√≥n de u...</td>\n",
       "      <td>q9i4uj</td>\n",
       "      <td>False</td>\n",
       "      <td>['ester', 'lamothe', 'ficci√≥n', 'villo', 'ac√°'...</td>\n",
       "      <td>ester lamothe ficci√≥n villo ac√° comedia pol√≠ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>pobre, servir, √©l, comida, ten√©s, culpa, onda,...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw6zvd</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>Eso porque son todos √∫tos chupa bija.. Venga e...</td>\n",
       "      <td>hgw2528</td>\n",
       "      <td>True</td>\n",
       "      <td>['√∫to', 'chupa', 'bijo', 'venir', 'ban', 'nedf...</td>\n",
       "      <td>√∫to chupa bijo venir ban nedflanducacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>re, cabeza, √©l, morir, pibes, papa, hambre, ri...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw24ns</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>mas verso burgu√©s que Maximo no hay. Es la rep...</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['verso', 'burgu√©s', 'maximo', 'representaci√≥n']</td>\n",
       "      <td>verso burgu√©s maximo representaci√≥n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.3722</td>\n",
       "      <td>√©l, recordar, pegar, √∫nico, robar, barrio, pen...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw38x8</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>Ayudar con comida? Na mejor unos afiches a tod...</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['ayudar', 'comida', 'na', 'afich', 'color']</td>\n",
       "      <td>ayudar comida na afich color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>the, of, necesitar, you, f√°cil, and, to, creer...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw2rml</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>1</td>\n",
       "      <td>¬øPor qu√© si es un cerdo tiene 6 patas?</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['cerdo', 'pata']</td>\n",
       "      <td>cerdo pata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>ah, /s, peronista, paso, x200b, mes, cagar, √©l...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw3wei</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>Mira, soy tan capitalista que por 15 mil pesos...</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['mira', 'capitalisto', 'pesos', 'corrijo', 'c...</td>\n",
       "      <td>mira capitalisto pesos corrijo color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>milei, pasar, debate, votar, voto, mujer, izqu...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw78bv</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>Swinetaur libertario de Darkest Per√≥nia. Ruin ...</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['swinetaur', 'libertario', 'darkest', 'per√≥ni...</td>\n",
       "      <td>swinetaur libertario darkest per√≥nia ruin come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>√©l, foto, ver, libertad, sacar, feriado, tomar...</td>\n",
       "      <td>1</td>\n",
       "      <td>hgw6rim</td>\n",
       "      <td>Memeüí©</td>\n",
       "      <td>0</td>\n",
       "      <td>como no pueden contra elllll. lo ensucian vamo...</td>\n",
       "      <td>q9hut7</td>\n",
       "      <td>False</td>\n",
       "      <td>['elllll', 'ensuciar', 'milie', 'bastar', 'k']</td>\n",
       "      <td>elllll ensuciar milie bastar k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Dominant_Topic  Perc_Contribution  \\\n",
       "0      0            12.0             0.2531   \n",
       "1      1             2.0             0.2598   \n",
       "2      2            26.0             0.3279   \n",
       "3      3             6.0             0.4349   \n",
       "4      4            21.0             0.8089   \n",
       "5      5            12.0             0.3722   \n",
       "6      6            17.0             0.3461   \n",
       "7      7            22.0             0.3515   \n",
       "8      8            24.0             0.4082   \n",
       "9      9            23.0             0.4081   \n",
       "\n",
       "                                      Topic_Keywords  score       id  \\\n",
       "0  √©l, recordar, pegar, √∫nico, robar, barrio, pen...      1  hgw77qe   \n",
       "1  perro, nik, meme, gobierno, explicar, it, teni...      1  hgw7dci   \n",
       "2  falacia, decir, gratis, k, joda, pa√≠s, mandar,...      1  hgw69er   \n",
       "3  pobre, servir, √©l, comida, ten√©s, culpa, onda,...      1  hgw6zvd   \n",
       "4  re, cabeza, √©l, morir, pibes, papa, hambre, ri...      1  hgw24ns   \n",
       "5  √©l, recordar, pegar, √∫nico, robar, barrio, pen...      1  hgw38x8   \n",
       "6  the, of, necesitar, you, f√°cil, and, to, creer...      1  hgw2rml   \n",
       "7  ah, /s, peronista, paso, x200b, mes, cagar, √©l...      1  hgw3wei   \n",
       "8  milei, pasar, debate, votar, voto, mujer, izqu...      1  hgw78bv   \n",
       "9  √©l, foto, ver, libertad, sacar, feriado, tomar...      1  hgw6rim   \n",
       "\n",
       "             flair  comms_num  \\\n",
       "0       Pol√≠ticaüèõÔ∏è          0   \n",
       "1       Pol√≠ticaüèõÔ∏è          0   \n",
       "2  Humor:snoo_joy:          0   \n",
       "3            Memeüí©          0   \n",
       "4            Memeüí©          0   \n",
       "5            Memeüí©          0   \n",
       "6            Memeüí©          1   \n",
       "7            Memeüí©          0   \n",
       "8            Memeüí©          0   \n",
       "9            Memeüí©          0   \n",
       "\n",
       "                                                body comment_parent_id  \\\n",
       "0  Iba a decir, bue si lo saco de su bolsillo... ...            q9imco   \n",
       "1                Se volvio un meme el bot del dolar?           hgw666m   \n",
       "2  Este Esteban Lamothe estaba en la ficci√≥n de u...            q9i4uj   \n",
       "3  Eso porque son todos √∫tos chupa bija.. Venga e...           hgw2528   \n",
       "4  mas verso burgu√©s que Maximo no hay. Es la rep...            q9hut7   \n",
       "5  Ayudar con comida? Na mejor unos afiches a tod...            q9hut7   \n",
       "6             ¬øPor qu√© si es un cerdo tiene 6 patas?            q9hut7   \n",
       "7  Mira, soy tan capitalista que por 15 mil pesos...            q9hut7   \n",
       "8  Swinetaur libertario de Darkest Per√≥nia. Ruin ...            q9hut7   \n",
       "9  como no pueden contra elllll. lo ensucian vamo...            q9hut7   \n",
       "\n",
       "   is_replay                                       lemma_tokens  \\\n",
       "0      False  ['bue', 'saco', 'bolsillo', 'recorder', 'hdp',...   \n",
       "1       True                        ['volvio', 'meme', 'dolar']   \n",
       "2      False  ['ester', 'lamothe', 'ficci√≥n', 'villo', 'ac√°'...   \n",
       "3       True  ['√∫to', 'chupa', 'bijo', 'venir', 'ban', 'nedf...   \n",
       "4      False   ['verso', 'burgu√©s', 'maximo', 'representaci√≥n']   \n",
       "5      False       ['ayudar', 'comida', 'na', 'afich', 'color']   \n",
       "6      False                                  ['cerdo', 'pata']   \n",
       "7      False  ['mira', 'capitalisto', 'pesos', 'corrijo', 'c...   \n",
       "8      False  ['swinetaur', 'libertario', 'darkest', 'per√≥ni...   \n",
       "9      False     ['elllll', 'ensuciar', 'milie', 'bastar', 'k']   \n",
       "\n",
       "                                  body_preprocessing  \n",
       "0  bue saco bolsillo recorder hdp mantener alcanz...  \n",
       "1                                  volvio meme dolar  \n",
       "2  ester lamothe ficci√≥n villo ac√° comedia pol√≠ti...  \n",
       "3           √∫to chupa bijo venir ban nedflanducacion  \n",
       "4                verso burgu√©s maximo representaci√≥n  \n",
       "5                       ayudar comida na afich color  \n",
       "6                                         cerdo pata  \n",
       "7               mira capitalisto pesos corrijo color  \n",
       "8  swinetaur libertario darkest per√≥nia ruin come...  \n",
       "9                     elllll ensuciar milie bastar k  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "#df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv(TEXT_SAVE_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}