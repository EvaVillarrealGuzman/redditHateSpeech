Caracterizaci√≥n de discurso de odio en r/argentina

---

√çndice
- [Vistazo r√°pido](#vistazo-r√°pido)
  - [Flujo de datos generados](#flujo-de-datos-generados)
- [Introducci√≥n](#introducci√≥n)
  - [Discurso de odio](#discurso-de-odio)
  - [reddit](#reddit)
  - [r/argentina](#rargentina)
- [Obtenci√≥n de datos](#obtenci√≥n-de-datos)
- [Pre-procesamiento](#pre-procesamiento)
- [Embeddings](#embeddings)
- [Entrenamiento de detector de odio](#entrenamiento-de-detector-de-odio)
- [Aplicaci√≥n del modelo a los comentarios](#aplicaci√≥n-del-modelo-a-los-comentarios)
- [An√°lisis de resultados](#an√°lisis-de-resultados)
- [Conclusiones](#conclusiones)
- [Trabajos futuros](#trabajos-futuros)
- [Texto no asignado](#texto-no-asignado)
- [Backlog](#backlog)
- [Fuentes consultadas para el trabajo](#fuentes-consultadas-para-el-trabajo)
  - [Discursos de odio](#discursos-de-odio)
  - [reddit API](#reddit-api)
  - [Procesamiento de lenguaje natural](#procesamiento-de-lenguaje-natural)
  - [Clustering](#clustering)
  - [Trabajos relacionados](#trabajos-relacionados)


## Vistazo r√°pido

El presente repo contiene el c√≥digo correspondiente al proyecto final de la materia [Miner√≠a de datos para texto](https://sites.google.com/unc.edu.ar/textmining2021/), a cargo de Laura Alonso i Alemany.

Objetivo del proyecto: Caracterizar discursos de odio dentro de la comunidad de [reddit Argentina](https://reddit.com/r/argentina). Esto es, detectarlos y encontrar sub-lenguajes de odio en los mismos.

Para realizar esto, se llev√≥ a cabo un proceso consistente en 5 etapas, como se muestra en la siguiente figura:

![pipeline_reddit](/misc/workflow.drawio.png)


Cada etapa tiene su correspondiente notebook:

1. Obtenci√≥n del conjunto de comentarios de a trav√©s de la API de Reddit ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/1_pipeline_download_reddit_comments.ipynb)).
   
2. Pre-procesamiento del mismo ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/2_pipeline_preprocessing.ipynb)).

3. Aplicaci√≥n de embeddings y categorizaci√≥n en cl√∫sters (notebook [LDA](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3a_pipeline_lda.ipynb) [Word2Vec](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3b_pipeline_embedding_word2vec.ipynb) [FastText](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3c_pipeline_embedding_fasttext.ipynb)).

4. Entrenamiento de un modelo de detecci√≥n de odio y extracci√≥n de palabras de odio en cada dataset ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/4_detect_hate_speech.ipynb)).
Para realizar el entrenamiento de los modelos, es necesario contar con los datasets respectivos de cada competencia (Hateval, DETOXIS, MeOffendMex) que se desee entrenar.

5. Uso del modelo para predecir los comentarios recolectados ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/5_pipeline_hate_speech.ipynb)).

6. Combinaci√≥n de dicho modelo con las categor√≠as encontradas para encontrar correlaciones ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/6_pipeline_result.ipynb)).

**Este informe y proyecto estan en proceso üößüî®, todav√≠a sujetos a cambios, correcciones, y mejoras**


### Flujo de datos generados

Los distintos notebooks forman un pipeline en el cu√°l cada uno utiliza los datos generados por el anterior. Se listan cada una de las entradas:

1. Obtenci√≥n de comentarios. 
    - Archivos de entrada: N/A. 
    - Archivo de salida: *docs/reddit_data.csv*: CSV que contiene los comentarios de reddit descargados

2. Pre-procesamiento del dataset.
    - Archivos de entrada: *docs/reddit_data.csv*.
    - Archivos de salida: *docs/preprocessing_reddit_data.csv*: CSV con los comentarios pre-procesados.
   

3. Embeddings y clustering.
    - Archivos de entrada: *docs/preprocessing_reddit_data.csv*.
    - Archivos de salida: 
      - *docs/reddit_data_<m√©todo>.csv*, donde *<m√©todo>* puede ser 'lda', o 'word2vec', 'fasttext'. Cada uno de estos archivos toma el dataset pre-procesado y le agrega el n√∫mero de cl√∫ster al que pertenecer√≠a cada comentario, seg√∫n su cercan√≠a.
      - *docs/models/<model>.model*, el modelo entrenado. Puede ser 'word2vec', o 'fasttext'. 
      - *docs/models/<model>_kmeans.model*, el modelo de k-means entrenado usando los embeddings de <model> (para 'word2vec' y 'fasttext').


4. Entrenamiento y selecci√≥n del modelo.
   - Archivos de entrada: *docs/hateval2019/hateval2019_es_train.csv*, *docs/detoxis_data/train.csv*, y *docs/MeOffendEs/mx-train-data-non-contextual.csv*. Estos archivos requieren la descarga previa manual de cada dataset.
   - Archivos de salida: para cada dataset, se guarda:
     - Palabras de odio de cada modelo: *docs/palabras_odio.csv*.
     - Vectorizador: *docs/models/<dataset>_vectorizer.pkl* donde *<dataset>* es hateval, detoxis, o meoffendmex.
     - Modelo entrenado: *docs/models/<dataset>_<iniciales_modelo>_model.pkl* donde *<iniciales_modelo>* es 'lr', 'rf', o 'nb'.
   - Archivos de salida (de prueba): Predicciones: *docs/test/reddit_<dataset>_hate_comments.csv*, uno para cada <dataset>: 'hateval', 'detoxis', 'meoffendmex'.
   
5. Aplicaci√≥n del modelo en comentarios de reddit. 
   - Archivos de entrada: *docs/reddit_data_<m√©todo>.csv*.
   - Archivos de salida:
     - *docs/reddit_data_hate_speech.csv* - CSV que toma  **TODO**
6. An√°lisis de resultados.
   - Archivos de entrada: *docs/reddit_data_hate_speech.csv*
   - Archivos de salida: N/A.
## Introducci√≥n

### Discurso de odio

Hay varias posturas sobre lo que es discurso de odio, en general se coincide en que es un discurso que:

1. Apunta a un grupo o individuo, basado en alg√∫n aspecto como su orientaci√≥n sexual, religi√≥n, nacionalidad, etc.
2. Busca humillar, discriminar o propagar el odio/hostilidad hacia ese grupo.
3. Tiene una intenci√≥n deliberada.

Su manifestaci√≥n en Internet, adem√°s:
1. Puede motivar formas de agresi√≥n en l√≠nea.
2. Permite propagar el discurso de odio con velocidad.
3. Permite que el discurso se mantenga y comparta con facilidad.
4. Facilita la generaci√≥n de c√°maras de eco.
5. Al estar en servidores privados, permite que ciertas empresas intenten eludir su control, y usarlos para mantener sus usuarios interactuando con el servicio.

### r/argentina

[Reddit](https://www.reddit.com/) es  una red social de ‚Äúcomunidades‚Äù creadas por usuarios. En este proyecto, nos centramos en [reddit argentina](https://www.reddit.com/r/argentina/).

En la siguiente imagen podemos ver la estructura general de un post en reddit:

![](misc/reddit.png)

En cada comunidad sus miembros hacen posts, y cada post puede ser comentado generando debate.

Su aspecto distintivo, es que cada post o comentario recibe votos, con el objetivo de que aquellos posts o comentarios que m√°s aportan aparezcan encima de los que no. Tambi√©n se pueden premiar a aquellos destacados.

## Obtenci√≥n de datos

Para la obtenci√≥n de los datos se utiliz√≥ un *wrapper* de la API de reddit, llamado [praw](https://praw.readthedocs.io/en/stable/index.html), a partir del cu√°l descargamos comentarios de diferentes *post* del *subreddit* argentina, as√≠ como las respuestas de los comentarios.
Los comentarios en reddit pueden ser *link* o pueden ser solo textos. Filtramos solamente los comentarios que tengan textos. A la vez solo se consideraron comentarios que tuvieran como m√≠nimo cierta cantidad de caracteres.

De cada comentario que se guard√≥ de reddit, se obtuvieron los siguientes datos:
- *id*: identificador de reddit. Se guard√≥ por cuestiones de trazabilidad.
- *comment_parent_id*: identificador del *post* o comentario al cu√°l responde el comentario actual en caso que corresponda. Se guard√≥ por cuestiones de trazabilidad.
- *flair*: es el tipo de comentario etiquetado por reddit, por ejemplo, pol√≠tica, econom√≠a, humor, etc.
- *comms_num*: n√∫mero de respuestas que recibi√≥ el comentaio.
- *score*: es un puntaje que los usuarios le dan al comentario.

## Pre-procesamiento

El pre-procesamiento consisti√≥ en:

- Eliminar emojis, urls, comillas, caracteres especiales, puntuaciones.
- Aplicar tokenizaci√≥n: en cada comentario, el token era la palabra.
- Conversi√≥n a min√∫scula.
- Eliminaci√≥n de stopwords utilizando spaCy.
- Lematizaci√≥n utilizando spaCy.
- Construir bigramas y trigramas.

## Embeddings

Para poder detectar las subcomunidades dentro de reddit comenzamos utilizando LDA. Sin embargo, los resultados que obtuvimos no fueron satisfactorios, ya que a la hora de realizar un an√°lisis de los t√≥picos identificados por el modelo, encontramos poca cohesi√≥n entre los temas.

A ra√≠z de esto, probamos con *word embedding* donde obtuvimos resultados que captan mucho mejor la sem√°ntica de la informaci√≥n. El proceso que llevamos a cabo en *word embedding* para obtener las subcomunidades fue:

1. Generar una representaci√≥n vectorial de los comentarios: se mapearon los comentarios a partir de palabras en vectores num√©ricos.
2. Aplicamos un algoritmo de *clustering*, particularmente *k-means*, donde las caracter√≠sticas que se pasaron son los vectores num√©ricos obtenidos en el paso anterior.

Utilizamos dos t√©cnicas de *word embedding*: primero usamos Word2Vec y luego FastText.

A continuaci√≥n mostramos algunos comentarios que fueron agrupados a trav√©s de las diferentes t√©cnicas aplicadas. Un evento particular que sucedi√≥ durante la descarga de estos datos en reddit fue el debate de la ley de etiquetados en Argentina. Vamos a comparar las subcomunidades obtenidos en cada t√©cnica analizando particularmente la subcomunidad referida a este evento.

### Embedding con LDA

En la siguiente imagen se pueden observar algunos de los t√≥picos identificados por LDA.

![](misc/embedding_1.png)

El t√≥pico n√∫mero 91, **piedra - etiqueta - pan - mira**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con la comida en general. Algunos comentarios son:

1. Me alegro mucho, seguro muy feliz todos por el reencuentro. Igual te recomiendo que no coma directo de la lata, pasale a un platito o comedero. Entiendo que a veces ni te dan tiempo.
2. Todo mi secundario el desayuno fue un fantoche triple y una lata de coca.  Y s√≥lo gastaba 2$. Qu√© buenos tiempos.
3. La manteca no hace mal. Es muy dif√≠cil comer exceso de grasas para tu cuerpo en comparaci√≥n con lo f√°cil que es atiborrarte con az√∫car y carbohidratos. Esos son los verdaderos enemigos
4. Y con etiquetas que te dicen cu√°nta grasa tiene un kilo de bayonesa
5. Alta banfest se van a mandar los mods con este thread. Despedite de tu cuenta, maquinola, denunciado

### Embedding con Word2Vec

En la siguiente imagen se pueden observar algunas de las subcominidades identificados por Word2Vec.

![](misc/embedding_2.png)

El *cluster* n√∫mero 94, **ley - etiquetado - proyecto**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con las leyes en general. Algunos comentarios son:

1. Una prueba mas de la ley de oferta y demanda
2. Con la nueva ley no le pod√©s regalar leche entera o un alfajor a un comedor, decir comida basura en un pa√≠s donde el 50% de los chicos no hacen toda las comidas es lo m√°s clasista que existe.
3. Recuerden la ley de alquileres.... Fu√© sancionada con un beso muy fuerte de los K, PRO y dem√°s muchachos...
4. No entiendo c√≥mo hay tanta gente en contra de una ley que no te cambia un carajo tu vida. Es la ley m√°s anodina que sac√≥ el Kirchnerismo en toda su historia creo
5. Pero hay leyes contra la violencia de genero! Como paso esto!!!1!?
6. No existe tal cosa en Argentina. Existe el Estado de Sitio, pero no se asemeja para nada a una ley marcial.. El concepto de ley marcial como tal, desapareci√≥ en el 94 con la nueva Constituci√≥n.

### Embedding con FastText

En la siguiente imagen se pueden observar algunas de las subcominidades identificados por FastText.

![](misc/embedding_3.png)

Como se puede ver en el cluster **jaja - jajaja - jajajar - jajajaja - jajaj**, FastText identifica mejor las alteraciones que pueden suceder dentro de una palabra.

El *cluster* n√∫mero 113, **ley - etiquetado - votar**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con las leyes en general. Algunos comentarios son:

1. Feriado con fines tur√≠sticos. Ley 27.399
2. ajajaja como los cagaron a los primeros. como siempre la ley aplica a todos por igual /s
3. El sticker en Chile fue durante la transici√≥n de la ley. Imag√≠nate tener productos fabricados y tener que cambiar la envoltura a todos para que cumplan la ley
4. Gracias gloriosa ley de regulaci√≥n de alimentos, ahora se que desayunar coca cola con surtidos bagleys esta mal
5. Eso y que la ley va a prohibir vender dulces y gaseosas en los colegios, y usar im√°genes de famosos en los envases.
6. Eso est√° por la ley Micaela no?. Tipo esta clase de capacitaciones no?
7. y ahora Lipovetzky reconoce lo de la ley de alquileres


## Entrenamiento de detector de odio

## Aplicaci√≥n del modelo a los comentarios

## An√°lisis de resultados


## Conclusiones

## Trabajos futuros
## Fuentes consultadas para el trabajo


### Discursos de odio

- https://en.wikipedia.org/wiki/Hate_speech
- https://www.rightsforpeace.org/hate-speech
- https://fsi.stanford.edu/news/reddit-hate-speech
- https://variety.com/2020/digital/news/reddit-bans-hate-speech-groups-removes-2000-subreddits-donald-trump-1234692898
- https://www.reddithelp.com/hc/en-us/articles/360045715951-Promoting-Hate-Based-on-Identity-or-Vulnerability

### reddit API

- https://www.jcchouinard.com/reddit-api/


### Procesamiento de lenguaje natural

- Foundations of Statistical Natural Language Processing - Manning & Sch√ºtze (1999)
- https://spacy.io
- https://radimrehurek.com/gensim/
- https://www.nltk.org
- https://www.baeldung.com/cs/ml-word2vec-topic-modeling
- https://www.kdnuggets.com/2018/04/robust-word2vec-models-gensim.html
- https://adrian-rdz.github.io/NLP_word2vec/
- https://towardsdatascience.com/applying-machine-learning-to-classify-an-unsupervised-text-document-e7bb6265f52
- https://dylancastillo.co/nlp-snippets-cluster-documents-using-word2vec/
- https://www.roelpeters.be/calculating-mutual-information-in-python/

### Clustering

- https://towardsdatascience.com/k-means-clustering-8e1e64c1561c
- https://paperperweek.wordpress.com/2018/04/09/best-ways-to-cluster-word2vec/
- https://ai.intelligentonlinetools.com/ml/k-means-clustering-example-word2vec/
- https://medium.com/@rohithramesh1991/unsupervised-text-clustering-using-natural-language-processing-nlp-1a8bc18b048d
- https://xplordat.com/2018/12/14/want-to-cluster-text-try-custom-word-embeddings/
- https://towardsdatascience.com/clustering-with-more-than-two-features-try-this-to-explain-your-findings-b053007d680a

### Trabajos relacionados

- https://github.com/jfreddypuentes/spanlp
- https://medium.com/ml2vec/using-word2vec-to-analyze-reddit-comments-28945d8cee57
- https://www.kaggle.com/szymonjanowski/internet-articles-data-with-users-engagement
- https://towardsdatascience.com/religion-on-twitter-5f7b84062304
- https://becominghuman.ai/detecting-gender-based-hate-speech-in-spanish-with-natural-language-processing-cdbba6ec2f8b
- https://www.learndatasci.com/tutorials/sentiment-analysis-reddit-headlines-pythons-nltk/
